% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/GenericML.R
\name{GenericML}
\alias{GenericML}
\title{Generic Machine Learning Inference}
\usage{
GenericML(
  Z,
  D,
  Y,
  learner.propensity.score = "constant",
  learners.genericML,
  num.splits = 100,
  Z_CLAN = NULL,
  HT.transformation = FALSE,
  X1.variables_BLP = list(functions_of_Z = c("B"), custom_covariates = NULL,
    fixed_effects = NULL),
  X1.variables_GATES = list(functions_of_Z = c("B"), custom_covariates = NULL,
    fixed_effects = NULL),
  quantile.cutoffs = c(0.25, 0.5, 0.75),
  differences.control_GATES = list(group.to.subtract.from = "most",
    groups.to.be.subtracted = 1),
  differences.control_CLAN = list(group.to.subtract.from = "most",
    groups.to.be.subtracted = 1),
  vcov.control_BLP = list(estimator = "vcovHC", arguments = list(type = "const")),
  vcov.control_GATES = list(estimator = "vcovHC", arguments = list(type = "const")),
  equal.group.variances_CLAN = FALSE,
  proportion.in.main.set = 0.5,
  significance.level = 0.05,
  minimum.variation = 1e-05,
  parallel = .Platform$OS.type == "unix",
  num.cores = parallel::detectCores(),
  seed = NULL,
  store.learners = FALSE,
  store.splits = FALSE
)
}
\arguments{
\item{Z}{A matrix or data frame of the covariates.}

\item{D}{A binary vector of treatment assignment.}

\item{Y}{The response vector.}

\item{learner.propensity.score}{The estimator for the propensity scores. Either a numeric vector (which is then taken as estimates of the propensity scores) or a string specifying the estimator. The string must either be equal to 'constant' (estimates the propensity scores by mean(D)), 'elastic.net', 'random.forest', 'tree', or mlr3 syntax. Example for the latter: mlr3::lrn("classif.ranger", num.trees = 500) for a classification forest.}

\item{learners.genericML}{A vector of strings specifying the machine learners to be used for estimating the BCA and CATE. Either \code{'elastic.net'}, \code{'random.forest'}, or \code{'tree'}. Can alternatively be specified by using \code{mlr3} syntax, for example \code{'mlr3::lrn("ranger", num.trees = 500)'}. See https://mlr3learners.mlr-org.com for a list of \code{mlr3} learners.}

\item{num.splits}{number of sample splits. Default is 100.}

\item{Z_CLAN}{A matrix of variables that shall be considered for the CLAN. If \code{NULL} (default), then \code{Z_CLAN = Z}, i.e. CLAN is performed for all variables in \code{Z}.}

\item{HT.transformation}{logical. If TRUE, a HT transformation is applied in BLP and GATES. Default is FALSE.}

\item{X1.variables_BLP}{a list controlling the variables that shall be used in the matrix X1 for the BLP regression. The first element of the list, functions_of_Z, needs to be a subset of c("S", "B", "p"), where "p" corresponds to the propensity scores (default is "B"). The second element, custom_covariates, is an optional matrix/data frame of custom covariates that shall be included in X1 (default is NULL). The third element, fixed_effects, is a vector of integers that indicates group membership of the observations: For each group, a fixed effect will be added (default is NULL for no fixed effects). Note that in the final matrix X1, a constant 1 will be silently included so that the regression model has an intercept.}

\item{X1.variables_GATES}{a list controlling the variables that shall be used in the matrix X1 for the GATES regression. The first element of the list, functions_of_Z, needs to be a subset of c("S", "B", "p"), where "p" corresponds to the propensity scores (default is "B"). The second element, custom_covariates, is an optional matrix/data frame of custom covariates that shall be included in X1 (default is NULL). The third element, fixed_effects, is a vector of integers that indicates group membership of the observations: For each group, a fixed effect will be added (default is NULL for no fixed effects). Note that in the final matrix X1, a constant 1 will be silently included if no HT transformation is applied so that the regression model has an intercept.}

\item{quantile.cutoffs}{The cutoff points of quantiles that shall be used for GATES grouping. Default is \code{c(0.25, 0.5, 0.75)}, which corresponds to the quartiles.}

\item{differences.control_GATES}{a list with two elements called 'group.to.subtract.from' and 'groups.to.be.subtracted'. The first element ('group.to.subtract.from') denotes what shall be the base group to subtract from in GATES; either "most" or "least". The second element ('groups.to.be.subtracted') are the groups to be subtracted from 'group.to.subtract.from', which is a subset of {1,...,K}, where K equals the number of groups.}

\item{differences.control_CLAN}{same as differences.control_GATES, just for CLAN.}

\item{vcov.control_BLP}{a list with two elements called 'estimator' and 'arguments'. The argument 'estimator' is a string specifying the covariance matrix estimator to be used in the BLP regression; specifies a covariance estimator function in the sandwich package (https://cran.r-project.org/web/packages/sandwich/sandwich.pdf). Recommended estimators are "vcovBS", "vcovCL", "vcovHAC", and "vcovHC". Default is 'vcovHC'. The element 'arguments' is a list of arguments that shall be passed to the function specified in the element 'estimator'. Default leads to the (homoskedastic) ordinary least squares covariance matrix estimator. See the reference manual of the sandwich package for details (https://cran.r-project.org/web/packages/sandwich/vignettes/sandwich.pdf).}

\item{vcov.control_GATES}{same as vcov.control_BLP, just for GATES regression}

\item{equal.group.variances_CLAN}{logical. If TRUE, the the two within-group variances of the most and least affected group in CLAN are assumed to be equal. Default is FALSE.}

\item{proportion.in.main.set}{proportion of samples that shall be in main set. Default is 0.5.}

\item{significance.level}{significance level for VEIN. Default is 0.05.}

\item{minimum.variation}{minimum variation of the predictions before random noise with distribution N(0, var(Y)/20) is added. Default is 1e-05.}

\item{parallel}{logical. If TRUE, parallel computing will be used. Currently only supported on Unix systems.}

\item{num.cores}{number of cores to be used in parallelization (if applicable).}

\item{seed}{random seed.}

\item{store.learners}{Logical. If TRUE, all intermediate results of the learners will be stored. Default is FALSE.}

\item{store.splits}{Logical. If \code{TRUE}, information on the sample splits will be stored. Default is \code{FALSE}.}
}
\description{
Performs generic machine learning inference as in Chernozhukov, Demirer, Duflo and Fern√°ndez-Val (2020). Link to working paper: \url{https://arxiv.org/abs/1712.04802}.
}
