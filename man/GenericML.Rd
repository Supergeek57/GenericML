% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/GenericML.R
\name{GenericML}
\alias{GenericML}
\title{Generic Machine Learning Inference}
\usage{
GenericML(
  Z,
  D,
  Y,
  learners_GenericML,
  learner_propensity_score = "constant",
  num_splits = 100,
  Z_CLAN = NULL,
  HT = FALSE,
  quantile_cutoffs = c(0.25, 0.5, 0.75),
  X1_BLP = setup_X1(),
  X1_GATES = setup_X1(),
  diff_GATES = setup_diff(),
  diff_CLAN = setup_diff(),
  vcov_BLP = setup_vcov(),
  vcov_GATES = setup_vcov(),
  equal_variances_CLAN = FALSE,
  prop_main = 0.5,
  significance_level = 0.05,
  min_variation = 1e-05,
  parallel = .Platform$OS.type == "unix",
  num_cores = parallel::detectCores(),
  seed = NULL,
  store_learners = FALSE,
  store_splits = FALSE
)
}
\arguments{
\item{Z}{A matrix or data frame of the covariates.}

\item{D}{A binary vector of treatment assignment.}

\item{Y}{The response vector.}

\item{learners_GenericML}{A vector of strings specifying the machine learners to be used for estimating the BCA and CATE. Either \code{'elastic_net'}, \code{'random_forest'}, or \code{'tree'}. Can alternatively be specified by using \code{mlr3} syntax \emph{without} specification if the learner is a regression learner or classification learner. Example: \code{'mlr3::lrn("ranger", num.trees = 500)'} for a random forest learner. Note that this is a string and the absence of the \code{classif.} or \code{regr.} keywords. See \url{https://mlr3learners.mlr-org.com} for a list of \code{mlr3} learners.}

\item{learner_propensity_score}{The estimator for the propensity scores. Either a numeric vector (which is then taken as estimates of the propensity scores) or a string specifying the estimator. The string must either be equal to \code{'constant'} (estimates the propensity scores by \code{mean(D)}), \code{'elastic_net'}, \code{'random_forest'}, \code{'tree'}, or \code{mlr3} syntax. Note that in case of \code{mlr3} syntax, do \emph{not} specify if the learner is a regression learner or classification learner; Example: \code{'mlr3::lrn("ranger", num.trees = 500)'} for a random forest learner. Note that this is a string and the absence of the \code{classif.} or \code{regr.} keywords.}

\item{num_splits}{Number of sample splits. Default is 100.}

\item{Z_CLAN}{A matrix of variables that shall be considered for the CLAN. Each column represents a variable for which CLAN shall be performed. If \code{NULL} (default), then \code{Z_CLAN = Z}, i.e. CLAN is performed for all variables in \code{Z}.}

\item{HT}{Logical. If \code{TRUE}, a HT transformation is applied in the BLP and GATES regressions. Default is \code{FALSE}.}

\item{quantile_cutoffs}{The cutoff points of quantiles that shall be used for GATES grouping. Default is \code{c(0.25, 0.5, 0.75)}, which corresponds to the four quartiles.}

\item{X1_BLP}{Specifies the design matrix \eqn{X_1} in the BLP regression. See the documentation of \code{\link{setup_X1}} for details.}

\item{X1_GATES}{Same as \code{X1_BLP}, just for the the GATES regression.}

\item{diff_GATES}{Specifies the generic targets of GATES. See the documentation of \code{\link{setup_diff}} for details.}

\item{diff_CLAN}{Same as \code{diff_GATES}, just for the CLAN generic targets.}

\item{vcov_BLP}{Specifies the covariance matrix estimator in the BLP regression. See the documentation of \code{\link{setup_vcov}} for details.}

\item{vcov_GATES}{Same as \code{vcov_BLP}, just for the GATES regression.}

\item{equal_variances_CLAN}{Logical. If \code{TRUE}, the the two within-group variances of the differences between the CLAN generic targets are assumed to be equal. Default is \code{FALSE}.}

\item{prop_main}{Proportion of samples that shall be in main set. Default is 0.5.}

\item{significance_level}{Significance level for VEIN. Default is 0.05.}

\item{min_variation}{Minimum variation of the predictions before random noise with distribution \eqn{N(0, var(Y)/20)} is added. Default is \code{1e-05}.}

\item{parallel}{Logical. If \code{TRUE}, parallel computing will be used. Currently only supported on Unix systems.}

\item{num_cores}{Number of cores to be used in parallelization (if applicable). Deafult is the number of cores on your machine.}

\item{seed}{Random seed. Default is \code{NULL} for no random seeding.}

\item{store_learners}{Logical. If \code{TRUE}, all intermediate results of the learners will be stored. Default is \code{FALSE}. \strong{Warning:} For large data sets and/or many splits in \code{num_splits}, having \code{store_learners = TRUE} might cause memory issues.}

\item{store_splits}{Logical. If \code{TRUE}, information on the sample splits will be stored. Default is \code{FALSE}.}
}
\value{
An object of the class \code{GenericML}.
}
\description{
Performs generic machine learning inference as in Chernozhukov, Demirer, Duflo and Fern√°ndez-Val (2020). Link to working paper: \url{https://arxiv.org/abs/1712.04802}.
}
